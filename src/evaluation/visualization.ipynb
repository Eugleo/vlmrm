{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "\n",
    "Install dependencies:\n",
    "\n",
    "```shell\n",
    "pip install jupyter altair altair_saver polars pyarrow anywidget ipywidgets\n",
    "```\n",
    "\n",
    "Then, as per the [CAIS tutorial](https://cluster.safe.ai/#jupyter-notebooks-on-the-cluster), start a new interactive node:\n",
    "\n",
    "```shell\n",
    "srun --partition=single --pty bash\n",
    "```\n",
    "\n",
    "Then note the port number from:\n",
    "\n",
    "```shell\n",
    "unset XDG_RUNTIME_DIR\n",
    "export NODEPORT=$(( $RANDOM + 1024 ))\n",
    "echo $NODEPORT\n",
    "jupyter notebook --no-browser --port=$NODEPORT\n",
    "```\n",
    "\n",
    "Then on you local machine run (filling in the port from above).\n",
    "\n",
    "```shell\n",
    "export NODEPORT=####\n",
    "ssh -t -t [your ssh alias for cais cluster] -L ${NODEPORT}:localhost:${NODEPORT} ssh -N compute-permanent-node-990 -L ${NODEPORT}:localhost:${NODEPORT}\n",
    "```\n",
    "\n",
    "Now, open your local browser and enter the URL from jupyter (`http://localhost:19303/?token=cb...`), or open VSCode and under Select Kernel choose \"Existing Jupyter Server\" and input it there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import altair as alt\n",
    "import polars as pl\n",
    "import sklearn.metrics as skm\n",
    "from IPython.display import clear_output, display\n",
    "from ipywidgets import HTML, Dropdown, HBox, Label, Output, VBox, Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper function that are not very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _metadata_cols(df: pl.DataFrame):\n",
    "    tasks = df.get_column(\"task\").unique().to_list()\n",
    "    default = [\n",
    "        \"path\",\n",
    "        \"task\",\n",
    "        \"model\",\n",
    "        \"reward\",\n",
    "        \"label\",\n",
    "        \"true_probability\",\n",
    "        \"probability\",\n",
    "    ]\n",
    "    return [c for c in df.columns if c not in tasks + default]\n",
    "\n",
    "\n",
    "def _max_prob(df: pl.DataFrame, col: str):\n",
    "    tasks = df.get_column(\"task\").unique().to_list()\n",
    "    return df.group_by([\"path\", \"task\", \"model\", \"reward\"]).agg(\n",
    "        # Extract the label with the highest probability\n",
    "        pl.col(\"label\").sort_by(col).last(),\n",
    "        pl.col(_metadata_cols(df)).first(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the latest experiment in `out` is loaded. You can change this manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory (os error 2): ../../out/Exp_20240313_084045/results.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_115220/2429921125.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;31m# Load the latest experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mexperiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../out\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlatest_experiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mexperiment_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatest_experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vlmrm-experiments/lib/python3.9/site-packages/polars/_utils/deprecation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             _rename_keyword_argument(\n\u001b[1;32m    132\u001b[0m                 \u001b[0mold_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             )\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/vlmrm-experiments/lib/python3.9/site-packages/polars/_utils/deprecation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             _rename_keyword_argument(\n\u001b[1;32m    132\u001b[0m                 \u001b[0mold_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             )\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/vlmrm-experiments/lib/python3.9/site-packages/polars/_utils/deprecation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             _rename_keyword_argument(\n\u001b[1;32m    132\u001b[0m                 \u001b[0mold_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             )\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/vlmrm-experiments/lib/python3.9/site-packages/polars/io/csv/functions.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(source, has_header, columns, new_columns, separator, comment_prefix, quote_char, skip_rows, dtypes, schema, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, use_pyarrow, storage_options, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0muse_pyarrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mraise_if_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_if_empty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     ) as data:\n\u001b[0;32m--> 397\u001b[0;31m         df = pl.DataFrame._read_csv(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mhas_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vlmrm-experiments/lib/python3.9/site-packages/polars/dataframe/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, source, has_header, columns, separator, comment_prefix, quote_char, skip_rows, dtypes, schema, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines)\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mprojection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_projection_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         self._df = PyDataFrame.read_csv(\n\u001b[0m\u001b[1;32m    750\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0minfer_schema_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory (os error 2): ../../out/Exp_20240313_084045/results.csv"
     ]
    }
   ],
   "source": [
    "# Load the latest experiment\n",
    "experiments = Path(\"../../out\").iterdir()\n",
    "latest_experiment = sorted(experiments, key=lambda d: d.stat().st_mtime)[-1]\n",
    "experiment_dir = latest_experiment\n",
    "\n",
    "df = pl.read_csv(experiment_dir / \"results.csv\")\n",
    "\n",
    "predicted_labels = _max_prob(df, \"probability\").rename({\"label\": \"predicted_label\"})\n",
    "true_labels = _max_prob(df, \"true_probability\").rename({\"label\": \"true_label\"})\n",
    "predictions = predicted_labels.join(\n",
    "    true_labels, on=[\"path\", \"task\", \"model\", \"reward\"] + _metadata_cols(df)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created the table `predictions`, containing the predictions of all model+reward combinations for all tasks and videos. Most visualizations will be okay with using this as a base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>path</th><th>task</th><th>model</th><th>reward</th><th>predicted_label</th><th>is_photorealistic</th><th>needs_temporal</th><th>stairs_direction</th><th>true_label</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>bool</td><td>bool</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;/data/datasets…</td><td>&quot;room_detection…</td><td>&quot;clip&quot;</td><td>&quot;logit&quot;</td><td>&quot;closet&quot;</td><td>true</td><td>true</td><td>&quot;stairs_up&quot;</td><td>&quot;stairs_down&quot;</td></tr><tr><td>&quot;/data/datasets…</td><td>&quot;room_detection…</td><td>&quot;clip&quot;</td><td>&quot;logit&quot;</td><td>&quot;stairs_down&quot;</td><td>true</td><td>true</td><td>&quot;stairs_down&quot;</td><td>&quot;stairs_down&quot;</td></tr><tr><td>&quot;/data/datasets…</td><td>&quot;room_detection…</td><td>&quot;clip&quot;</td><td>&quot;logit&quot;</td><td>&quot;stairs_down&quot;</td><td>true</td><td>true</td><td>&quot;stairs_down&quot;</td><td>&quot;stairs_down&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 9)\n",
       "┌────────────┬────────────┬───────┬────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ path       ┆ task       ┆ model ┆ reward ┆ … ┆ is_photore ┆ needs_temp ┆ stairs_dir ┆ true_label │\n",
       "│ ---        ┆ ---        ┆ ---   ┆ ---    ┆   ┆ alistic    ┆ oral       ┆ ection     ┆ ---        │\n",
       "│ str        ┆ str        ┆ str   ┆ str    ┆   ┆ ---        ┆ ---        ┆ ---        ┆ str        │\n",
       "│            ┆            ┆       ┆        ┆   ┆ bool       ┆ bool       ┆ str        ┆            │\n",
       "╞════════════╪════════════╪═══════╪════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ /data/data ┆ room_detec ┆ clip  ┆ logit  ┆ … ┆ true       ┆ true       ┆ stairs_up  ┆ stairs_dow │\n",
       "│ sets/habit ┆ tion       ┆       ┆        ┆   ┆            ┆            ┆            ┆ n          │\n",
       "│ at_recordi ┆            ┆       ┆        ┆   ┆            ┆            ┆            ┆            │\n",
       "│ ng…        ┆            ┆       ┆        ┆   ┆            ┆            ┆            ┆            │\n",
       "│ /data/data ┆ room_detec ┆ clip  ┆ logit  ┆ … ┆ true       ┆ true       ┆ stairs_dow ┆ stairs_dow │\n",
       "│ sets/habit ┆ tion       ┆       ┆        ┆   ┆            ┆            ┆ n          ┆ n          │\n",
       "│ at_recordi ┆            ┆       ┆        ┆   ┆            ┆            ┆            ┆            │\n",
       "│ ng…        ┆            ┆       ┆        ┆   ┆            ┆            ┆            ┆            │\n",
       "│ /data/data ┆ room_detec ┆ clip  ┆ logit  ┆ … ┆ true       ┆ true       ┆ stairs_dow ┆ stairs_dow │\n",
       "│ sets/habit ┆ tion       ┆       ┆        ┆   ┆            ┆            ┆ n          ┆ n          │\n",
       "│ at_recordi ┆            ┆       ┆        ┆   ┆            ┆            ┆            ┆            │\n",
       "│ ng…        ┆            ┆       ┆        ┆   ┆            ┆            ┆            ┆            │\n",
       "└────────────┴────────────┴───────┴────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on `predictions`, we can calculate metrics for each task, model, reward combination. Feel free to add more here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>task</th><th>model</th><th>reward</th><th>f1</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;room_detection…</td><td>&quot;clip&quot;</td><td>&quot;logit&quot;</td><td>0.466667</td></tr><tr><td>&quot;room_detection…</td><td>&quot;clip&quot;</td><td>&quot;projection_0.0…</td><td>0.466667</td></tr><tr><td>&quot;room_detection…</td><td>&quot;clip&quot;</td><td>&quot;projection_0.2…</td><td>0.285714</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 4)\n",
       "┌────────────────┬───────┬─────────────────┬──────────┐\n",
       "│ task           ┆ model ┆ reward          ┆ f1       │\n",
       "│ ---            ┆ ---   ┆ ---             ┆ ---      │\n",
       "│ str            ┆ str   ┆ str             ┆ f64      │\n",
       "╞════════════════╪═══════╪═════════════════╪══════════╡\n",
       "│ room_detection ┆ clip  ┆ logit           ┆ 0.466667 │\n",
       "│ room_detection ┆ clip  ┆ projection_0.0  ┆ 0.466667 │\n",
       "│ room_detection ┆ clip  ┆ projection_0.25 ┆ 0.285714 │\n",
       "└────────────────┴───────┴─────────────────┴──────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A wrapper around a sklearn metric function\n",
    "def f1(group: pl.Series):\n",
    "    # group is a pl.Series object with two named fields, true_label and predicted_label\n",
    "    # we can access those fields using group.struct.field\n",
    "    return skm.f1_score(\n",
    "        y_true=group.struct.field(\"true_label\").to_numpy(),\n",
    "        y_pred=group.struct.field(\"predicted_label\").to_numpy(),\n",
    "        average=\"macro\",\n",
    "    )\n",
    "\n",
    "\n",
    "# A helper function used to extract label colums from the dataframe,\n",
    "# package them as structs, and then map matric_fun over them\n",
    "def compute_metric(metric_fun):\n",
    "    return pl.struct(\"true_label\", \"predicted_label\").map_batches(metric_fun).first()\n",
    "\n",
    "\n",
    "metrics = predictions.group_by(\"task\", \"model\", \"reward\").agg(\n",
    "    f1=compute_metric(f1),\n",
    "    # ...add more here!\n",
    ")\n",
    "\n",
    "metrics.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a table with metrics, we can plot it. We use `altair` because it allows for the type of interactivity we need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-48d95d6273014b85aea465da53cc0d4f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-48d95d6273014b85aea465da53cc0d4f.vega-embed details,\n",
       "  #altair-viz-48d95d6273014b85aea465da53cc0d4f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-48d95d6273014b85aea465da53cc0d4f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-48d95d6273014b85aea465da53cc0d4f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-48d95d6273014b85aea465da53cc0d4f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-9bcc270e23280d75e2e9511a65caed52\"}, \"facet\": {\"column\": {\"field\": \"model\", \"type\": \"nominal\"}, \"row\": {\"field\": \"task\", \"type\": \"nominal\"}}, \"spec\": {\"mark\": {\"type\": \"bar\", \"width\": 10}, \"encoding\": {\"color\": {\"field\": \"model\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"f1\", \"type\": \"quantitative\"}, {\"field\": \"model\", \"type\": \"nominal\"}, {\"field\": \"reward\", \"type\": \"nominal\"}], \"x\": {\"field\": \"reward\", \"type\": \"nominal\"}, \"y\": {\"field\": \"f1\", \"type\": \"quantitative\"}}}, \"title\": \"F1 score\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-9bcc270e23280d75e2e9511a65caed52\": [{\"task\": \"room_detection\", \"model\": \"clip\", \"reward\": \"logit\", \"f1\": 0.4666666666666667}, {\"task\": \"room_detection\", \"model\": \"clip\", \"reward\": \"projection_0.0\", \"f1\": 0.4666666666666667}, {\"task\": \"room_detection\", \"model\": \"clip\", \"reward\": \"projection_0.25\", \"f1\": 0.2857142857142857}, {\"task\": \"room_detection\", \"model\": \"clip\", \"reward\": \"projection_0.50\", \"f1\": 0.2222222222222222}, {\"task\": \"room_detection\", \"model\": \"clip\", \"reward\": \"projection_0.75\", \"f1\": 0.2222222222222222}, {\"task\": \"room_detection\", \"model\": \"clip\", \"reward\": \"projection_1.0\", \"f1\": 0.2}, {\"task\": \"clip_through_detection\", \"model\": \"clip\", \"reward\": \"logit\", \"f1\": 0.42857142857142855}, {\"task\": \"clip_through_detection\", \"model\": \"clip\", \"reward\": \"projection_0.0\", \"f1\": 0.42857142857142855}, {\"task\": \"clip_through_detection\", \"model\": \"clip\", \"reward\": \"projection_0.25\", \"f1\": 0.42857142857142855}, {\"task\": \"clip_through_detection\", \"model\": \"clip\", \"reward\": \"projection_0.50\", \"f1\": 1.0}, {\"task\": \"clip_through_detection\", \"model\": \"clip\", \"reward\": \"projection_0.75\", \"f1\": 1.0}, {\"task\": \"clip_through_detection\", \"model\": \"clip\", \"reward\": \"projection_1.0\", \"f1\": 1.0}, {\"task\": \"has_tv\", \"model\": \"clip\", \"reward\": \"logit\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"clip\", \"reward\": \"projection_0.0\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"clip\", \"reward\": \"projection_0.25\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"clip\", \"reward\": \"projection_0.50\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"clip\", \"reward\": \"projection_0.75\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"clip\", \"reward\": \"projection_1.0\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"clip\", \"reward\": \"logit\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"clip\", \"reward\": \"projection_0.0\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"clip\", \"reward\": \"projection_0.25\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"clip\", \"reward\": \"projection_0.50\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"clip\", \"reward\": \"projection_0.75\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"clip\", \"reward\": \"projection_1.0\", \"f1\": 0.4666666666666667}, {\"task\": \"has_toilet\", \"model\": \"clip\", \"reward\": \"logit\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"clip\", \"reward\": \"projection_0.0\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"clip\", \"reward\": \"projection_0.25\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"clip\", \"reward\": \"projection_0.50\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"clip\", \"reward\": \"projection_0.75\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"clip\", \"reward\": \"projection_1.0\", \"f1\": 1.0}, {\"task\": \"interact_drop\", \"model\": \"clip\", \"reward\": \"logit\", \"f1\": 0.0}, {\"task\": \"interact_drop\", \"model\": \"clip\", \"reward\": \"projection_0.0\", \"f1\": 0.0}, {\"task\": \"interact_drop\", \"model\": \"clip\", \"reward\": \"projection_0.25\", \"f1\": 0.0}, {\"task\": \"interact_drop\", \"model\": \"clip\", \"reward\": \"projection_0.50\", \"f1\": 0.0}, {\"task\": \"interact_drop\", \"model\": \"clip\", \"reward\": \"projection_0.75\", \"f1\": 0.0}, {\"task\": \"interact_drop\", \"model\": \"clip\", \"reward\": \"projection_1.0\", \"f1\": 0.0}, {\"task\": \"interact_open\", \"model\": \"clip\", \"reward\": \"logit\", \"f1\": 0.0}, {\"task\": \"interact_open\", \"model\": \"clip\", \"reward\": \"projection_0.0\", \"f1\": 0.0}, {\"task\": \"interact_open\", \"model\": \"clip\", \"reward\": \"projection_0.25\", \"f1\": 0.07407407407407407}, {\"task\": \"interact_open\", \"model\": \"clip\", \"reward\": \"projection_0.50\", \"f1\": 0.2}, {\"task\": \"interact_open\", \"model\": \"clip\", \"reward\": \"projection_0.75\", \"f1\": 0.2}, {\"task\": \"interact_open\", \"model\": \"clip\", \"reward\": \"projection_1.0\", \"f1\": 0.4666666666666667}, {\"task\": \"room_detection\", \"model\": \"viclip\", \"reward\": \"logit\", \"f1\": 0.4666666666666667}, {\"task\": \"room_detection\", \"model\": \"viclip\", \"reward\": \"projection_0.0\", \"f1\": 0.4666666666666667}, {\"task\": \"room_detection\", \"model\": \"viclip\", \"reward\": \"projection_0.25\", \"f1\": 0.2857142857142857}, {\"task\": \"room_detection\", \"model\": \"viclip\", \"reward\": \"projection_0.50\", \"f1\": 0.2222222222222222}, {\"task\": \"room_detection\", \"model\": \"viclip\", \"reward\": \"projection_0.75\", \"f1\": 0.0}, {\"task\": \"room_detection\", \"model\": \"viclip\", \"reward\": \"projection_1.0\", \"f1\": 0.1111111111111111}, {\"task\": \"clip_through_detection\", \"model\": \"viclip\", \"reward\": \"logit\", \"f1\": 0.2}, {\"task\": \"clip_through_detection\", \"model\": \"viclip\", \"reward\": \"projection_0.0\", \"f1\": 0.2}, {\"task\": \"clip_through_detection\", \"model\": \"viclip\", \"reward\": \"projection_0.25\", \"f1\": 0.2}, {\"task\": \"clip_through_detection\", \"model\": \"viclip\", \"reward\": \"projection_0.50\", \"f1\": 0.2727272727272727}, {\"task\": \"clip_through_detection\", \"model\": \"viclip\", \"reward\": \"projection_0.75\", \"f1\": 0.4666666666666667}, {\"task\": \"clip_through_detection\", \"model\": \"viclip\", \"reward\": \"projection_1.0\", \"f1\": 1.0}, {\"task\": \"has_tv\", \"model\": \"viclip\", \"reward\": \"logit\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"viclip\", \"reward\": \"projection_0.0\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"viclip\", \"reward\": \"projection_0.25\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"viclip\", \"reward\": \"projection_0.50\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"viclip\", \"reward\": \"projection_0.75\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"viclip\", \"reward\": \"projection_1.0\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"viclip\", \"reward\": \"logit\", \"f1\": 1.0}, {\"task\": \"has_plant\", \"model\": \"viclip\", \"reward\": \"projection_0.0\", \"f1\": 1.0}, {\"task\": \"has_plant\", \"model\": \"viclip\", \"reward\": \"projection_0.25\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"viclip\", \"reward\": \"projection_0.50\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"viclip\", \"reward\": \"projection_0.75\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"viclip\", \"reward\": \"projection_1.0\", \"f1\": 0.4666666666666667}, {\"task\": \"has_toilet\", \"model\": \"viclip\", \"reward\": \"logit\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"viclip\", \"reward\": \"projection_0.0\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"viclip\", \"reward\": \"projection_0.25\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"viclip\", \"reward\": \"projection_0.50\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"viclip\", \"reward\": \"projection_0.75\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"viclip\", \"reward\": \"projection_1.0\", \"f1\": 1.0}, {\"task\": \"interact_drop\", \"model\": \"viclip\", \"reward\": \"logit\", \"f1\": 0.07407407407407407}, {\"task\": \"interact_drop\", \"model\": \"viclip\", \"reward\": \"projection_0.0\", \"f1\": 0.07407407407407407}, {\"task\": \"interact_drop\", \"model\": \"viclip\", \"reward\": \"projection_0.25\", \"f1\": 0.0}, {\"task\": \"interact_drop\", \"model\": \"viclip\", \"reward\": \"projection_0.50\", \"f1\": 0.0}, {\"task\": \"interact_drop\", \"model\": \"viclip\", \"reward\": \"projection_0.75\", \"f1\": 0.0}, {\"task\": \"interact_drop\", \"model\": \"viclip\", \"reward\": \"projection_1.0\", \"f1\": 0.0}, {\"task\": \"interact_open\", \"model\": \"viclip\", \"reward\": \"logit\", \"f1\": 0.3333333333333333}, {\"task\": \"interact_open\", \"model\": \"viclip\", \"reward\": \"projection_0.0\", \"f1\": 0.3333333333333333}, {\"task\": \"interact_open\", \"model\": \"viclip\", \"reward\": \"projection_0.25\", \"f1\": 0.38461538461538464}, {\"task\": \"interact_open\", \"model\": \"viclip\", \"reward\": \"projection_0.50\", \"f1\": 0.4666666666666667}, {\"task\": \"interact_open\", \"model\": \"viclip\", \"reward\": \"projection_0.75\", \"f1\": 0.4666666666666667}, {\"task\": \"interact_open\", \"model\": \"viclip\", \"reward\": \"projection_1.0\", \"f1\": 1.0}, {\"task\": \"room_detection\", \"model\": \"s3d\", \"reward\": \"logit\", \"f1\": 0.1818181818181818}, {\"task\": \"room_detection\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"f1\": 0.0}, {\"task\": \"room_detection\", \"model\": \"s3d\", \"reward\": \"projection_0.25\", \"f1\": 0.0}, {\"task\": \"room_detection\", \"model\": \"s3d\", \"reward\": \"projection_0.50\", \"f1\": 0.0}, {\"task\": \"room_detection\", \"model\": \"s3d\", \"reward\": \"projection_0.75\", \"f1\": 0.0}, {\"task\": \"room_detection\", \"model\": \"s3d\", \"reward\": \"projection_1.0\", \"f1\": 0.0}, {\"task\": \"clip_through_detection\", \"model\": \"s3d\", \"reward\": \"logit\", \"f1\": 0.0}, {\"task\": \"clip_through_detection\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"f1\": 1.0}, {\"task\": \"clip_through_detection\", \"model\": \"s3d\", \"reward\": \"projection_0.25\", \"f1\": 1.0}, {\"task\": \"clip_through_detection\", \"model\": \"s3d\", \"reward\": \"projection_0.50\", \"f1\": 1.0}, {\"task\": \"clip_through_detection\", \"model\": \"s3d\", \"reward\": \"projection_0.75\", \"f1\": 1.0}, {\"task\": \"clip_through_detection\", \"model\": \"s3d\", \"reward\": \"projection_1.0\", \"f1\": 1.0}, {\"task\": \"has_tv\", \"model\": \"s3d\", \"reward\": \"logit\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"s3d\", \"reward\": \"projection_0.25\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"s3d\", \"reward\": \"projection_0.50\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"s3d\", \"reward\": \"projection_0.75\", \"f1\": 0.4666666666666667}, {\"task\": \"has_tv\", \"model\": \"s3d\", \"reward\": \"projection_1.0\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"s3d\", \"reward\": \"logit\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"s3d\", \"reward\": \"projection_0.25\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"s3d\", \"reward\": \"projection_0.50\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"s3d\", \"reward\": \"projection_0.75\", \"f1\": 0.4666666666666667}, {\"task\": \"has_plant\", \"model\": \"s3d\", \"reward\": \"projection_1.0\", \"f1\": 0.4666666666666667}, {\"task\": \"has_toilet\", \"model\": \"s3d\", \"reward\": \"logit\", \"f1\": 0.2}, {\"task\": \"has_toilet\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"s3d\", \"reward\": \"projection_0.25\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"s3d\", \"reward\": \"projection_0.50\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"s3d\", \"reward\": \"projection_0.75\", \"f1\": 1.0}, {\"task\": \"has_toilet\", \"model\": \"s3d\", \"reward\": \"projection_1.0\", \"f1\": 1.0}, {\"task\": \"interact_drop\", \"model\": \"s3d\", \"reward\": \"logit\", \"f1\": 0.13333333333333333}, {\"task\": \"interact_drop\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"f1\": 0.0}, {\"task\": \"interact_drop\", \"model\": \"s3d\", \"reward\": \"projection_0.25\", \"f1\": 0.0}, {\"task\": \"interact_drop\", \"model\": \"s3d\", \"reward\": \"projection_0.50\", \"f1\": 0.0}, {\"task\": \"interact_drop\", \"model\": \"s3d\", \"reward\": \"projection_0.75\", \"f1\": 0.0}, {\"task\": \"interact_drop\", \"model\": \"s3d\", \"reward\": \"projection_1.0\", \"f1\": 0.0}, {\"task\": \"interact_open\", \"model\": \"s3d\", \"reward\": \"logit\", \"f1\": 0.2}, {\"task\": \"interact_open\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"f1\": 1.0}, {\"task\": \"interact_open\", \"model\": \"s3d\", \"reward\": \"projection_0.25\", \"f1\": 1.0}, {\"task\": \"interact_open\", \"model\": \"s3d\", \"reward\": \"projection_0.50\", \"f1\": 1.0}, {\"task\": \"interact_open\", \"model\": \"s3d\", \"reward\": \"projection_0.75\", \"f1\": 1.0}, {\"task\": \"interact_open\", \"model\": \"s3d\", \"reward\": \"projection_1.0\", \"f1\": 1.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_metric(metric_name):\n",
    "    return (\n",
    "        alt.Chart(metrics.to_pandas())\n",
    "        .mark_bar(width=10)\n",
    "        .encode(\n",
    "            x=\"reward\",\n",
    "            y=metric_name,\n",
    "            color=\"model\",\n",
    "            tooltip=[metric_name, \"model\", \"reward\"],\n",
    "        )\n",
    "        .facet(column=\"model\", row=\"task\")\n",
    "        .properties(title=\"F1 score\")\n",
    "    )\n",
    "\n",
    "\n",
    "plot_metric(\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make the plot above but compute the metrics separately based on different metadata values, e.g. `is_photorealistic`. For brevity, we only plot the best-performing model+reward combination per model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-b8b91fd88ee94a7f9e0106c2ff912350.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-b8b91fd88ee94a7f9e0106c2ff912350.vega-embed details,\n",
       "  #altair-viz-b8b91fd88ee94a7f9e0106c2ff912350.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-b8b91fd88ee94a7f9e0106c2ff912350\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b8b91fd88ee94a7f9e0106c2ff912350\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b8b91fd88ee94a7f9e0106c2ff912350\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-09414872b33590d41983bc885910de54\"}, \"facet\": {\"column\": {\"field\": \"is_photorealistic\", \"title\": \"Was the video photorealistic?\", \"type\": \"nominal\"}, \"row\": {\"field\": \"task\", \"title\": \"Task\", \"type\": \"nominal\"}}, \"spec\": {\"mark\": {\"type\": \"bar\", \"width\": 10}, \"encoding\": {\"color\": {\"field\": \"model\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"f1\", \"type\": \"quantitative\"}, {\"field\": \"model\", \"type\": \"nominal\"}, {\"field\": \"reward\", \"type\": \"nominal\"}], \"x\": {\"field\": \"f1\", \"title\": \"Macro-averaged F1 Score\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"evaluator\", \"title\": \"\", \"type\": \"nominal\"}}, \"width\": 160}, \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"title\": \"F1 Score in Different Tasks, Photorealistic v. CAD Model\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-09414872b33590d41983bc885910de54\": [{\"task\": \"room_detection\", \"model\": \"clip\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 0.46153846153846156, \"evaluator\": \"clip + logit\"}, {\"task\": \"room_detection\", \"model\": \"clip\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"clip + logit\"}, {\"task\": \"clip_through_detection\", \"model\": \"clip\", \"reward\": \"projection_0.50\", \"is_photorealistic\": true, \"f1\": 1.0, \"evaluator\": \"clip + projection_0.50\"}, {\"task\": \"clip_through_detection\", \"model\": \"clip\", \"reward\": \"projection_0.50\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"clip + projection_0.50\"}, {\"task\": \"has_tv\", \"model\": \"clip\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 0.46153846153846156, \"evaluator\": \"clip + logit\"}, {\"task\": \"has_tv\", \"model\": \"clip\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"clip + logit\"}, {\"task\": \"has_plant\", \"model\": \"clip\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 0.46153846153846156, \"evaluator\": \"clip + logit\"}, {\"task\": \"has_plant\", \"model\": \"clip\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"clip + logit\"}, {\"task\": \"has_toilet\", \"model\": \"clip\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 1.0, \"evaluator\": \"clip + logit\"}, {\"task\": \"has_toilet\", \"model\": \"clip\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"clip + logit\"}, {\"task\": \"interact_drop\", \"model\": \"clip\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 0.0, \"evaluator\": \"clip + logit\"}, {\"task\": \"interact_drop\", \"model\": \"clip\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 0.0, \"evaluator\": \"clip + logit\"}, {\"task\": \"interact_open\", \"model\": \"clip\", \"reward\": \"projection_1.0\", \"is_photorealistic\": true, \"f1\": 1.0, \"evaluator\": \"clip + projection_1.0\"}, {\"task\": \"interact_open\", \"model\": \"clip\", \"reward\": \"projection_1.0\", \"is_photorealistic\": false, \"f1\": 0.0, \"evaluator\": \"clip + projection_1.0\"}, {\"task\": \"room_detection\", \"model\": \"viclip\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 1.0, \"evaluator\": \"viclip + logit\"}, {\"task\": \"room_detection\", \"model\": \"viclip\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 0.0, \"evaluator\": \"viclip + logit\"}, {\"task\": \"clip_through_detection\", \"model\": \"viclip\", \"reward\": \"projection_1.0\", \"is_photorealistic\": true, \"f1\": 1.0, \"evaluator\": \"viclip + projection_1.0\"}, {\"task\": \"clip_through_detection\", \"model\": \"viclip\", \"reward\": \"projection_1.0\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"viclip + projection_1.0\"}, {\"task\": \"has_tv\", \"model\": \"viclip\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 0.46153846153846156, \"evaluator\": \"viclip + logit\"}, {\"task\": \"has_tv\", \"model\": \"viclip\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"viclip + logit\"}, {\"task\": \"has_plant\", \"model\": \"viclip\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 1.0, \"evaluator\": \"viclip + logit\"}, {\"task\": \"has_plant\", \"model\": \"viclip\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"viclip + logit\"}, {\"task\": \"has_toilet\", \"model\": \"viclip\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 1.0, \"evaluator\": \"viclip + logit\"}, {\"task\": \"has_toilet\", \"model\": \"viclip\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"viclip + logit\"}, {\"task\": \"interact_drop\", \"model\": \"viclip\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 0.08333333333333333, \"evaluator\": \"viclip + logit\"}, {\"task\": \"interact_drop\", \"model\": \"viclip\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 0.0, \"evaluator\": \"viclip + logit\"}, {\"task\": \"interact_open\", \"model\": \"viclip\", \"reward\": \"projection_1.0\", \"is_photorealistic\": true, \"f1\": 1.0, \"evaluator\": \"viclip + projection_1.0\"}, {\"task\": \"interact_open\", \"model\": \"viclip\", \"reward\": \"projection_1.0\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"viclip + projection_1.0\"}, {\"task\": \"room_detection\", \"model\": \"s3d\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 0.14814814814814814, \"evaluator\": \"s3d + logit\"}, {\"task\": \"room_detection\", \"model\": \"s3d\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"s3d + logit\"}, {\"task\": \"clip_through_detection\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"is_photorealistic\": true, \"f1\": 1.0, \"evaluator\": \"s3d + projection_0.0\"}, {\"task\": \"clip_through_detection\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"s3d + projection_0.0\"}, {\"task\": \"has_tv\", \"model\": \"s3d\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 0.46153846153846156, \"evaluator\": \"s3d + logit\"}, {\"task\": \"has_tv\", \"model\": \"s3d\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"s3d + logit\"}, {\"task\": \"has_plant\", \"model\": \"s3d\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 0.46153846153846156, \"evaluator\": \"s3d + logit\"}, {\"task\": \"has_plant\", \"model\": \"s3d\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"s3d + logit\"}, {\"task\": \"has_toilet\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"is_photorealistic\": true, \"f1\": 1.0, \"evaluator\": \"s3d + projection_0.0\"}, {\"task\": \"has_toilet\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"s3d + projection_0.0\"}, {\"task\": \"interact_drop\", \"model\": \"s3d\", \"reward\": \"logit\", \"is_photorealistic\": true, \"f1\": 0.08333333333333333, \"evaluator\": \"s3d + logit\"}, {\"task\": \"interact_drop\", \"model\": \"s3d\", \"reward\": \"logit\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"s3d + logit\"}, {\"task\": \"interact_open\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"is_photorealistic\": true, \"f1\": 1.0, \"evaluator\": \"s3d + projection_0.0\"}, {\"task\": \"interact_open\", \"model\": \"s3d\", \"reward\": \"projection_0.0\", \"is_photorealistic\": false, \"f1\": 1.0, \"evaluator\": \"s3d + projection_0.0\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_per_photorealistic = predictions.group_by(\n",
    "    \"task\", \"model\", \"reward\", \"is_photorealistic\"\n",
    ").agg(\n",
    "    f1=compute_metric(f1),\n",
    "    # ...add more here!\n",
    ")\n",
    "\n",
    "best_models = metrics.group_by(\"task\", \"model\").agg(\n",
    "    pl.col(\"reward\").sort_by(\"f1\", descending=True).first()\n",
    ")\n",
    "\n",
    "# The metrics_per_photorealistic table filtered to only contain the best models\n",
    "# i.e. exactly one model+reward per task+is_photorealistic\n",
    "metrics_per_photorealistic = metrics_per_photorealistic.join(\n",
    "    best_models, on=[\"task\", \"model\", \"reward\"], how=\"semi\"\n",
    ").with_columns(evaluator=pl.concat_str(\"model\", \"reward\", separator=\" + \"))\n",
    "\n",
    "(\n",
    "    alt.Chart(metrics_per_photorealistic.to_pandas(), width=160)\n",
    "    .mark_bar(width=10)\n",
    "    .encode(\n",
    "        x=alt.X(\"f1\", title=\"Macro-averaged F1 Score\"),\n",
    "        y=alt.Y(\"evaluator\", title=\"\"),\n",
    "        color=\"model\",\n",
    "        tooltip=[\"f1\", \"model\", \"reward\"],\n",
    "    )\n",
    "    .facet(row=alt.Row(\"task\", title=\"Task\"), column=alt.Column(\"is_photorealistic\", title=\"Was the video photorealistic?\"))\n",
    "    .resolve_scale(y=\"independent\")\n",
    "    .properties(title=\"F1 Score in Different Tasks, Photorealistic v. CAD Model\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the plotting needs will probably be taken care of by the above, or small variations of it. Below we have the interactive confusion matrix; the code there shouldn't be too important to fully understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart(task, model):\n",
    "    # A table of best model+reard combination for each model and task\n",
    "    best_models = metrics.group_by(\"task\", \"model\").agg(\n",
    "        pl.col(\"reward\").sort_by(\"f1\", descending=True).first()\n",
    "    )\n",
    "\n",
    "    # The predictions table filtered to only contain the best models\n",
    "    # i.e. exactly one model+reward per task\n",
    "    best_model_predicitons = predictions.filter(\n",
    "        pl.col(\"task\") == task, pl.col(\"model\") == model\n",
    "    ).join(best_models, on=[\"task\", \"model\", \"reward\"], how=\"semi\")\n",
    "\n",
    "    true_label_size = best_model_predicitons.group_by(\n",
    "        \"model\", \"reward\", \"true_label\"\n",
    "    ).agg(pl.len().alias(\"true_label_size\"))\n",
    "\n",
    "    # A normal confusion matrix\n",
    "    confusion_matrix = (\n",
    "        best_model_predicitons.join(\n",
    "            true_label_size, on=[\"model\", \"reward\", \"true_label\"]\n",
    "        )\n",
    "        .group_by(\"model\", \"reward\", \"true_label\", \"predicted_label\")\n",
    "        .agg(count=pl.len(), ratio=pl.len() / pl.col(\"true_label_size\").first())\n",
    "    )\n",
    "\n",
    "    # Needed to register the click events\n",
    "    selection = alt.selection_point(\n",
    "        fields=[\"true_label\", \"predicted_label\"], name=\"selection\"\n",
    "    )\n",
    "\n",
    "    # Base chart to which we'll add layers later\n",
    "    base = (\n",
    "        alt.Chart(confusion_matrix.to_pandas())\n",
    "        .encode(\n",
    "            x=\"predicted_label\",\n",
    "            y=\"true_label\",\n",
    "        )\n",
    "        .properties(title=f\"{model}, {task}\")\n",
    "    )\n",
    "\n",
    "    # Heatmap layer\n",
    "    heatmap = base.mark_rect().encode(\n",
    "        color=alt.Color(\"ratio\").scale(scheme=\"blues\"),\n",
    "        tooltip=[\"true_label\", \"predicted_label\", \"count\", \"ratio\"],\n",
    "    )\n",
    "\n",
    "    # Diagonal frames layer\n",
    "    labels = confusion_matrix[\"true_label\"].unique()\n",
    "    diag_df = pl.DataFrame({\"predicted_label\": labels, \"true_label\": labels})\n",
    "    diagonal = (\n",
    "        alt.Chart(pl.DataFrame(diag_df).to_pandas())\n",
    "        .mark_rect(stroke=\"black\", strokeWidth=1, fillOpacity=0)\n",
    "        .encode(x=\"predicted_label\", y=\"true_label\")\n",
    "    )\n",
    "\n",
    "    # Text labels in cells\n",
    "    text = base.mark_text(baseline=\"middle\").encode(\n",
    "        alt.Text(\"ratio\", format=\".1~f\"),\n",
    "        color=alt.condition(\n",
    "            alt.datum.ratio < 0.5, alt.value(\"black\"), alt.value(\"white\")\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Add the layers together and also add the click-selector from eariler\n",
    "    # Returning this would give us a normal chart, like the one above\n",
    "    chart = (heatmap + diagonal + text).add_params(selection)\n",
    "\n",
    "    # Wrap the chart in a Jupyter widget\n",
    "    jchart = alt.JupyterChart(chart)\n",
    "\n",
    "    # This is the vertical box the videos will live in\n",
    "    videos_widget = VBox()\n",
    "\n",
    "    # Click callback\n",
    "    def on_select(change):\n",
    "        if change.new.value is None:\n",
    "            return\n",
    "\n",
    "        paths = []\n",
    "\n",
    "        for sel in change.new.value:\n",
    "            # Get a list of videos that correspond to the cell that was clicked on\n",
    "            paths.extend(\n",
    "                best_model_predicitons.filter(\n",
    "                    pl.col(\"model\") == model,\n",
    "                    pl.col(\"task\") == task,\n",
    "                    pl.col(\"true_label\") == sel[\"true_label\"],\n",
    "                    pl.col(\"predicted_label\") == sel[\"predicted_label\"],\n",
    "                )\n",
    "                .get_column(\"path\")\n",
    "                .to_list()\n",
    "            )\n",
    "        # Load the videos based on the paths above, and put them into a flexbox\n",
    "        videos = []\n",
    "        for path in paths:\n",
    "            video = Video.from_file(path)\n",
    "            video.autoplay = True\n",
    "            video.loop = True\n",
    "            videos.append(VBox([video, Label(\"👆 \" + path)]))\n",
    "\n",
    "        videos_widget.children = videos\n",
    "\n",
    "    # Whenever the selection in the chart changes, call the callback above\n",
    "    jchart.selections.observe(on_select, [\"selection\"])\n",
    "\n",
    "    return HBox([jchart, videos_widget])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the cell below, you can pick the model and task combination and also click the cells in the matrix to see which videos ended up in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed310f16bb714eac9ce7591967bf4a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Task:', options=('clip_through_detection', 'has_plant', 'has_toilet', 'ha…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb4e5219d4a466a855ea81902f90b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a task selection dropdown\n",
    "tasks = predictions.get_column(\"task\").unique().sort()\n",
    "task_dropdown = Dropdown(\n",
    "    options=tasks,\n",
    "    value=tasks[0],\n",
    "    description=\"Task:\",\n",
    ")\n",
    "\n",
    "# Create a model selection dropdown\n",
    "models = predictions.get_column(\"model\").unique().sort()\n",
    "model_dropdown = Dropdown(\n",
    "    options=models,\n",
    "    value=models[0],\n",
    "    description=\"Model:\",\n",
    ")\n",
    "\n",
    "# Create an \"output\", a sort of a canvas that we can render things into\n",
    "# This is needed for the live updates whenever the dropdowns change\n",
    "output = Output()\n",
    "\n",
    "\n",
    "def on_change(_change):\n",
    "    with output:\n",
    "        # Clear the canvas and render the new plot\n",
    "        clear_output()\n",
    "        display(chart(task_dropdown.value, model_dropdown.value))\n",
    "\n",
    "\n",
    "model_dropdown.observe(on_change, names=[\"value\"])\n",
    "task_dropdown.observe(on_change, names=[\"value\"])\n",
    "\n",
    "# Render the dropdowns in Jupyter\n",
    "display(VBox([task_dropdown, model_dropdown]))\n",
    "\n",
    "with output:\n",
    "    # Redner the chart into the output\n",
    "    display(chart(task_dropdown.value, model_dropdown.value))\n",
    "\n",
    "# Render the output in Jupyter\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
